
\chapter{基于渐进式策略的人体运动姿态预测算法}
本章节将围绕本文的两个主要贡献点：渐进式的网络学习框架和集成$SD-GCN$和$TD-GCN$的图卷积模块。分别从动机、方案、实现框架和算法细节几个方面对本方法进行详细的阐述。在此之前，我们首先通过数学语言定义人体运动姿态预测问题，并介绍在此过程中使用的相关数据结构，以方便在本文后续章节中进行准确的叙述。
\section{数据描述与问题定义}
\subsection{人体运动姿态数据结构}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\textwidth]{FigMa/show_structure.png}\\
    \vspace{-0.3cm}
    \caption{人体运动姿态数据结构}
    \label{fig:data_structure}
\end{figure}
首先我们介绍人体运动姿态预测问题所使用的数据结构。如图\ref{fig:data_structure}左所示，人体运动数据是通过动作捕捉设备，在封闭室内或开放室外场景提取到的人体关键点运动数据，这些数据以SKT（Skeletal Kinematic Tree）的形式表示和存储。在实际动作捕捉过程中，通常只关注在运动过程中起决定性作用的关节点，例如手肘、肩部、膝盖等。这些关节点在\ref{fig:data_structure}左中以红色标记的形式展现。其中位于胯部的五角星节点被称为根节点，其余节点通过递归的形式计算自身对于根节点的相对位置来得到自身位置。由于本文仅关注三维欧式空间中的人体运动，因此，我们用与根节点的相对3D坐标来描述每个关节点空间位置。将独立的关节点按照人体结构连接后，即可得到抽象后人体姿态。由于我们处理的是序列数据，同时包含时间和空间两个维度的关节点，因此在\ref{fig:data_structure}右中，空间维度上描述人体结构信息，时间维度上描述关节点序列运动信息。

\subsection{人体运动姿态预测问题定义}
从数学上，对于一个长度为$T$的人体运动序列，我们将其定义为$S_{1:T} = \{P_1,P_2,\cdots,P_{T}\}$，其中$P_i$当前运动序列中位于$i$时刻的人体姿态。每个人体姿态$P_i$又由若干个关节点组成其中$P \in \mathbb{R}^M$，$M$为该人体姿态包含的关节点数量，每个关节点又由一个$D$维的向量描述。

对于人体运动姿态预测问题，网络$\Phi$接收已知输入序列$S_{1:T_h} = \{P_1,P_2,\cdots,P_{T_h}\}$作为输入，预测未来运动序列$S_{T_h+1:T_h+T_f} = \{P_{T_h+1},P_{T_h+2},\cdots,P_{T_h+T_f}\}$，这一过程的数学描述如公式\ref{equation:problem_formulation}所示。其中$\theta$为可训练的网络参数。
\begin{equation}
    S_{T_h+1:T_h+T_f} = \Phi(S_{1:T_h}, \theta) \label{equation:problem_formulation}
\end{equation}

\section{渐进式人体运动序列预测框架}
正如\ref{section:1.1}节所提到的，预测过程中的不确定性是影响预测精确度进一步提升的关键因素，而这种不确定性来自输入运动序列和待预测序列之间的差异。简而言之，由于输入运动序列和预测运动序列之间存在较大差异（例如，输入运动和待预测运动的运动模式有较大差异），网络无法根据输入序列中的信息来准确推测未来运动，导致预测结果脱离真实情况。因此，如何降低预测过程中的不确定性成为了当务之急。

在调研过程中，我们注意到LTD\parencite{mao2019learning}提出的一项改进使得预测精度相较于现有方法得到了极大提升。在早期的方法中，如公式\ref{equation:problem_formulation}所示，输入运动序列长度$1:T_h$与预测序列长度$T_h+1:T_h+T_f$通常存在差异，通常预测序列的长度要远远长于输入序列（例如，输入10帧预测25帧），这使得网络需要在毫无参考基础的情况下去构造未来运动序列。这通常会导致预测结果不连续，与真值出现较大偏差。针对该现象，LTD\parencite{mao2019learning}提出公式\ref{equation:padding},通过使用输入序列的最后一帧来填充输入序列，使得输入序列的长度和预测序列保持一致。
\begin{equation}
    \begin{aligned}
        &\widetilde{S}_{1:T_h} = [S_{1:T_h}, \{P^{T_h+1}_{T_h}, \cdots, P^{T_f}_{T_h} \} ]
        \\
        &S_{T_h+1:T_h+T_f} = \Phi(\widetilde{S}_{1:T_h}, \theta)
    \end{aligned}
    \label{equation:padding}
\end{equation}

从图\ref{fig:LTD_padding}可以看到，经过填充后的输入数据对网络有两点促进作用，第一，输入和输出维度一致，避免了数据维度变换过程中的不确定性。第二，网络在预测未来序列时可以在已知部分最后一帧基础上进行预测，降低了预测的难度。
\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{FigMa/LTD_padding.png}\\
    \vspace{-0.3cm}
    \caption{LTD数据填充过程}
    \label{fig:LTD_padding}
\end{figure}
然而这种粗糙的填补方法也有其固有缺陷。首先整个填充过程不区分时序距离，全部使用最后一帧进行填充，对于离$P_{T_h}$较近的未来运动，$P_{T_h}$还能提供一定的参考。随着时间向前，未来帧与$P_{T_h}$的关联越来越弱，其提供的参考价值也越来越低，预测的不确定性也逐渐增加。因此该填充方法无法缓解较远距离的预测不确定问题。

在分析上述方法得失后，我们认为，缩小输入序列和待预测序列的差异（维度差异、内容差异等）可以有效降低预测过程中的不确定性，使得预测结果向我们期望的方向趋近。但单纯地填充输入序列最后一帧所带来的性能提升还有一定的上涨空间。如何为预测过程提更高效的预测基础将是需要重点考虑的问题。

受到最近被广泛应用的由粗糙到精细（Coarse To Fine）策略的启发，我们设计了一个简易实验来验证我们的想法。Coarse to fine 策略与大多数一步到位的方法不同，预测被分为了两个阶段。位于网络浅层的阶段被称为粗糙（Coarse）网络，它接收原始的输入，并输出一个较为粗糙的结果，虽然该结果离最终的目标存在一定的偏差，但与最初的输入信息相比，它已经包含了目标的绝大部分信息。随后该粗糙结果被送入精修（Fine）网络，精修网络将在粗糙网络的基础上进一步完善预测细节。该策略被广泛应用于图片修复（Image Inpainting）\parencite{yu2018generative,zamir2021multi}领域，原始缺失图片通常由粗糙网络生成一个低分辨率较模糊的修复版本，此次修复的目的是修复图片内容的结构。随后，粗修版本被送入精修网络提高分辨率并进一步完善细节，最后输出高质量的修复结果。参考该思路，我们设计了一个Coarse To Fine 人体运动序列预测网络。

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{FigMa/Two_stage.png}\\
    \vspace{-0.3cm}
    \caption{Coarse To Fine 预测网络}
    \label{fig:Two_stage}
\end{figure}

在最初的粗修阶段，我们任然保留了LTD中基于最后一帧的填充步骤，因为通过此步骤可以保证网络输入输出维度一致，减少预测维度上的不确定性。经过填充后的输入序列经过粗修网络，预测得到一个较为粗糙的结果，该结果受到中级监督目标的监督。该中级监督目标相比较最终的预测目标，去除了部分运动细节，只保留了运动大致趋势，通过缩小输入信息与预测目标之间的差距，降低了预测过程的不确定性。随后，粗糙的预测结果被送入后续的精修网络，进一步丰富动作的细节。此时，预测结果受到原始真值的监督，以期望获得与真值一致的结果。该模型通过两阶段的结构，将预测过程拆分为两个部分，每个部分的预测不可确定性得到了减少。预测精确性与单阶段的LTD网络相比有显著提升，这一结果在实验部分有所证明。
\subsection{多阶段预测网络框架}
随后我们进一步拓展了该过程，将一个两阶段的Coarse To Fine网络拓展为多阶段的网络。通过对预测过程的进一步细分，每个阶段的预测难度被进一步降低，网络也容易做出准确的预测。我们将多阶段的网络模型定义如下。
\begin{equation}
    \begin{aligned}
         \hat{S}_{1:L}^{1} &= \Phi^1([{S}_{1:T_h};P_{T_h},\cdots,P_{T_h}]), \\
        \hat{S}_{1:L}^{i} &= \Phi^i([S_{1:T_h};\hat{S}_{T_h+1:L}^{i-1}]), i = {2,3,\cdots,T},
    \end{aligned}
    \label{equation:multi-stage_formulation}
\end{equation}
公式\ref{equation:multi-stage_formulation}中，现有方法中单阶段的预测过程$\Phi$被拆分为多个阶段$\Phi = \{ \Phi_1, \cdots, \Phi_T\}$，每个阶段在上一个阶段的预测基础上，不断完善预测精度，使得预测精确度不断稳步提升，相比较现有的单阶段网络，多阶段网络预测过程更加可控，每阶段的预测结构都受到与之对应的中级监督目标的监督，此外预测任务的细分也使得每阶段网络的预测不确定性进一步降低，预测难度也进一步降低。为此，我们设计了一个多阶段的网络，其网络结构图如图\ref{fig:multi_stage}所示。

多阶段的网络设计包含两点，第一是每个阶段（Stage）的子网络设计，在这里我们最初使用了LTD中提出的GCN模块（在文章后续内容中我们提出了具有更强时空信息提取能力的GCN模块用以替换）。每个子网络内部为一个解码器编码器网络（Encoder-Decoder），编码器解码器结构对称。内部由多个GCB（GCN Block）构成，每个GCB又由两个GCL（GCN Layer）构成，GCL是网络的最基本的构成结构，其具体结构如图\ref{equation:multi-stage_formulation}右下角所示，GCL由一个GCN、BatchNorm、Tanh和DropOut组成，可以完成最基本的人体运动数据时空信息提取功能。值得注意的是，网络的规模并不随着阶段数量的增加而提升，在我们的设计中，网络中的GCB数量固定，随着阶段的增加，每个阶段包含的GCB数量成比例下降。
\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{FigMa/multi-stage_network.png}\\
    \vspace{-0.3cm}
    \caption{多阶段的预测网络}
    \label{fig:multi_stage}
\end{figure}
网络参数量的增加在一定范围下提高了网络的容量和表达能力，但当突破某一阈值的时候网络复杂度增加带来的计算开销负担抵消了这一优势。因此我们的多阶段网络，在提升网络性能的同时，并没有提高网络的复杂程度和计算开销。
第二是，中级监督目标的设计，中级监督目标必须具有层次化特点，遵循由简单到复杂的原则，浅层网络负责较为简单的处理大致框架的任务，而深层网络负责较为复杂的细节完善任务。在其他类型任务（图像等规则数据）的中级监督目标设计中，可以简单地通过降低分辨率、模糊处理和提取边缘特征等方式降低图片的细节和提取内容的结构信息来构造中级监督目标。但人体运动姿态数据是不规则的图状数据，并且已经高度抽象。无法通过寻常的降维手段提取结构信息或降低运动复杂度。虽然当前也有一些方法，如MSR\parencite{dang2021msr}提出在空间维度上对人体结构进行降维，合并运动模型类似的相邻关节点来减少图中的关节点数量。该方法建立了空间层次化的中级监督目标，但该方法破坏了重要的人体结构先验信息，导致渐进式的策略发挥了极其有效的作用。

\subsection{基于累积均值平滑的中级监督目标}
因此我们设计了一种适用于人体运动姿态时空数据的中级监督目标构建方法，该方法可以在时间维度上降低数据的运动复杂度，同时保持原有的空间结构，以便后续网络提取其中的人体结构先验信息。具体的，我们在不同阶段对关节点轨迹施加不同强度的平滑算法。网络浅层因为表达能力不足，因此其对应的中级监督目标被施加了更强的平滑来降低运动的复杂度和预测难度。随着网络深入，网络的表达能力增加，能够承担更复杂的预测任务，此时，对于中级监督目标的平滑程度就会被削弱，以帮助其在之前阶段的预测基础上，丰富结果的细节。为此，我们设计了一种名为累积均值平滑（Accumulated Average Smoothing）的方法构造用于人体运动姿态序列中级监督目标。

在介绍累积均值平滑算法之前，为了方便叙述，我们首先给出人体运动模型中关节点轨迹的数学定义。假设每个姿态包含$M$个关节点，每个关节点由$D$维的向量描述。一个人体运动姿态序列$S_{1:L}$包含$M \times D$条轨迹：$\{T_j|j\in[1, M\times D]\}$，每条轨迹$T_j$由同一个关节点的某位维度上的运动组成：$T_j=\{x^i_j|i\in[1,L]\}$。由于所有轨迹都由同样的平滑方法处理，因此在下面的叙述中我们忽略了不同轨迹的区别，统一用$T$代称$T_j$。

$T$由两部分组成：已知的运动序列$\{x^i|i\in[1,T_h]\}$和待预测的运动序列$\{x^i|i\in[T_h+1,T_h+T_f]\}$。由于已知的运动序列属于模型的输入数据，不需要预测，所以不需要经过累积平滑算法处理。待预测的运动序列是网络需要预测的部分，需要用累积平滑算法调节该部分数据的预测难度。目前被广泛使用的平滑方式是基于高斯卷积核的滤波器。高斯滤波器被广泛应用于图像平滑领域，它是一种常见的线性滤波器。它的原理是将一个二维高斯分布函数应用于图像的每一个像素，使得该像素周围的像素加权平均起来，从而达到平滑图像的目的。高斯滤波器的核心是高斯核（Gaussian kernel），也称为卷积核（Convolution Kernel）或滤波器（Filter）。高斯核是一个二维高斯分布函数，它的中心是图像上的当前像素点。高斯核中的每个元素表示该位置的权重，越靠近中心位置的像素权重越高，越远离中心位置的像素权重越低。通常情况下，高斯核是一个奇数×奇数的矩阵，这样可以保证中心像素的位置。在轨迹平滑算法中，2D的高斯卷积核退化为一维，其卷积核权重计算公式为：
\begin{equation}
    G(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{x^2}{2\sigma^2}}
    \label{equation:gauss_filter}
\end{equation}
其中$x$表示当前位置相对于卷积核中心的距离，$\sigma$表示标准差，标准差越大越靠近卷积核中心的权重越高，反之权重分布越平均。
\begin{equation}
    G = \frac{1}{\sqrt{2\pi}\sigma}
        \begin{bmatrix}e^{-\frac{-{((N-1)/2)} ^2}{2\sigma^2}} & \cdots & e^{-\frac{-{((N-1)/2)}^2}{2\sigma^2}} \\ 
        \vdots & \ddots & \vdots \\
        e^{-\frac{0^2}{2\sigma^2}} & \cdots & e^{-\frac{0^2}{2\sigma^2}} \\
        \vdots & \ddots & \vdots \\
        e^{-\frac{{((N-1)/2)}^2}{2\sigma^2}} & \cdots & e^{-\frac{{((N-1)/2)}^2}{2\sigma^2}
        }\end{bmatrix}
    \label{equation:gauss_filter_mat}
\end{equation}
如果需要生成一个$N\times 1$的高斯卷积核，可以将上述公式\ref{equation:gauss_filter}代入矩阵形式，得到卷积核矩阵\ref{equation:gauss_filter_mat}，其中，$G$ 是 $N\times 1$ 的高斯卷积核矩阵，$N$ 表示卷积核的大小。

由于在本问题中，只需要对一条轨迹待预测部分进行平滑，已知的运动序列保持不变即可。而高斯滤波器在对轨迹进行处理时，不可必要的需要计算卷积核范围内的所有阶段数据，因此在已知运动序列和待预测部分的过渡部分会出现跳跃（Jump）现象，这是由于高斯滤波器在计算过渡部分的平滑值时，将卷积核范围内已知运动序列纳入计算。而已知运动序列并没有进行平滑操作，所以导致计算结果在该处出现了跳跃现象。此外，由于高斯滤波器在计算时，其节点原始值的权重较高，导致平滑力度不足，难以构造层次化的中级监督目标。

因此，我们提出了累积均值平滑算法来解决以上两个问题。我们将该算法定义如下：

\begin{equation}
    \bar{x}^i = \frac{1}{i-T_h}\sum_{k=T_h+1}^{i}x^k, \forall i\in[T_h+1, T_h+T_f].
    \label{equation:AAS}
\end{equation}

待预测部分的某个节点的平滑值由其之前所有节点的累计平均值得到。首先平滑值计算过程只涉及待预测部分，不涉及已知部分，这就避免了出现过渡部分的跳跃问题。其次，平滑值由该节点前面的所有节点的均值得到，不存在原始节点权重过高影响平滑结果的问题。并且越远离已知部分的的节点，由于进行平滑计算参与的节点数量增加，所受到的平滑力度越大。反之越靠近已知部分的节点保留的原始信息也越多。该特性也符合直觉，离已知部分越近的节点预测时的不确定性越低，预测难度也更低，因此可以基本保留原始信息以获得准确的结果。而离已知部分较远的节点，不确定性高，预测难度大需要通过更强的平滑力度来降低网络的预测难度。总之，累积均值平滑算法相比传统的高斯滤波算法能够生成过渡更平滑，难度梯度更合理的中级监督目标，能有效地帮助网络建立一个渐进式的学习框架，降低预测难度，提高网络学习效率。

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{FigMa/AAS.png}\\
    \vspace{-0.3cm}
    \caption{累积均值平滑对比高斯滤波}
    \label{fig:AAS}
\end{figure}